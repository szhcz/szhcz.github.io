[{"title":"OPERA：通过过度信任惩罚和回顾分配减轻多模态大语言模型中的幻觉","date":"2024-08-15T16:00:00.000Z","url":"/posts/OPERA-Alleviating-Hallucination-in-Multi-Modal-Large-Language-Models/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["大模型安全-幻觉","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8-%E5%B9%BB%E8%A7%89/"]],"categories":[["大模型安全","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"],["幻觉","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E5%B9%BB%E8%A7%89/"]],"content":"1. 研究背景、动机、主要贡献(Why)1.1 研究背景最近多模态大语言模型的发展使基础模型能够让用户使用图像作为输入进行交互。MLLM 的能力使其能够胜任各种视觉任务。 MLLM 也面临着“幻觉”问题。例如，产生不相关或无意义的响应，识别图像中不存在的颜色、数量和位置方面不准确的对象。这一缺陷给 MLLM 成为值得信赖的助手的实际应用带来了巨大的风险。例如，在模型辅助自动驾驶场景中，这种对道路场景图像的误解可能会导致系统的错误判断并导致严重的交通事故。 1.2 存在问题(动机)1.2.1 现有方案缺点 方法会产生大量的额外成本，包括用于训练的额外指令数据的注释预算、外部知识或模型的集成 1.3 主要贡献 无需引入任何外部数据、知识或额外的培训。 我们揭示了幻觉和过度信任模式的出现，并提出了一种配备回顾重新分配策略的基于惩罚的解码方法。 包括GPT 评估在内的广泛评估证明了OPERA 的卓越性能，它几乎可以作为缓解幻觉的免费午餐。 2. 论文提出的新方法(What)2.1 制定 MLLM 的生成过程2.1.1 输入构造MLLM 的输入包含 图像 MLLM 通常使用视觉编码器从原始图像中提取视觉标记 将视觉标记表示为 。这里N是视觉标记的长度，在大多数情况下它是固定的数字 并使用跨模态映射模块将它们映射到 LLM 的输入空间。 文本。 输入文本使用分词器进行分词 将其表示为。 图像和文本标记连接起来作为最终的输入序列，我们将其表示为， T = N + M 。 2.1.2 模型前向传播 MLLM 使用因果注意掩码以自回归方式进行训练，每个标记根据先前的标记预测其下一个标记。 Causal Mask 主要用于限定模型的可视范围，防止模型看到未来的数据。 h 是 MLLM 最后一层的输出隐藏状态，包含了模型对输入序列的编码和理解 e.g. 假设有一个 MLLM 模型，输入一个句子 \"The weather is nice today.\"，模型经过处理后会有一个隐藏状态 “h”，这个隐藏状态包含了模型对整个句子的编码表示。 假设 “h” 是一个包含 512 维度的向量，其中每个维度可能对应于句子中的不同语义特征。 MLLM 使用词汇头 来投影隐藏状态 h 并获取下一个标记预测的 logits（或概率） e.g. 词汇头，通常是指用于将隐藏状态映射为词汇表中每个单词的概率分布的神经网络层。这个层通常是一个全连接层，其输出是一个向量，每个元素对应于词汇表中一个单词的概率。这个输出向量可以通过 softmax 函数转换为概率分布，用于生成下一个可能的标记。 假设我们有一个掩码语言模型（MLLM），输入是一个经过编码后的序列的隐藏状态 “h”，我们想要预测下一个单词。 假设我们的词汇表中有以下单词：[“speak”, “I”, “Chinese”, “can”]。 现在，我们将隐藏状态 “h” 经过词汇头的处理，得到一个包含四个元素的向量，分别对应于词汇表中的每个单词。这个向量可以表示为 [0.1, 0.6, 0.2, 0.1]。 通过 softmax 函数，我们可以将这个向量转换为概率分布。经过 softmax 处理后，我们得到的概率分布如下所示： “speak”: “I”: “Chinese”: “can”: 2.1.3 解码OPERA 基于 Beam Search这是一种基于累积分数的解码策略。简而言之，对于给定的束大小，束搜索保留候选序列，其中每个候选序列都是带有波束分数的解码序列。当解码 token 时，每个候选假设将根据 logits 中的 Top-概率选择 候选 token。最后，解码过程将输出假设赢得最佳波束分数。 e.g. 2.2 过度信任惩罚2.2.1 前置背景在浅层中，标签词从演示中收集信息以形成语义表示以进行更深入的处理，而深层则从标签词中提取并利用这些信息来制定最终预测。 可视化自注意力图。 非对角线元素表示模型在生成当前输出标记时对其他输入位置的关注程度。 柱状注意力模式通常表现在缺乏大量信息的标记上，例如句号或引号。 柱状注意力模式的令牌通常拥有有限的信息，但却对所有后续令牌的预测产生显着影响。 (a) 聚合模式与最近的“锚定令牌”观察结果一致。 (b)、(c) 显示当上下文中出现更多锚标记时，5,000 张随机选择的 MSCOCO 图像上的 CHAIR 分数（更多幻觉）不断增加。 知识聚合后面的内容大部分都带有推理或者幻觉 2.2.2 具体方法幻觉和知识聚合模式之间存在高概率的共存。然而，这种模式具有显着的滞后性，即，当对应的令牌被解码时，不能立即观察到模式，而是在后续的几个令牌被解码之后，幻觉可能已经发生。为了应对滞后现象，我们提出了“过度信任惩罚”。 当前生成的序列 下一个标志词预测的因果自注意力权重causual self-attention weights 考虑在局部窗口中收集所有先前的自注意力权重来表征知识模式，即局部窗口注意力定义为 其中 k 表示我们在注意力图上裁剪的局部窗口的大小，表示第 j 个标记分配给第 i 个标记的注意力权重 预处理，用零填充矩阵的上三角形并放大注意力值其中为零，σ 是可配置的比例因子。 对注意力矩阵的下三角进行列乘法，并获得列分数向量。直观上，分数越大表示相应位置存在的模式越强。因此，我们选择列向得分向量的最大值作为知识聚合模式的特征。 2.3 回顾-分配策略通常，惩罚项能够惩罚具有知识聚合模式的候选者，并鼓励其他候选者被预测。但也有少数情况是，所有候选者都受到惩罚，而幻觉已经出现。 这个案例促使我们重新思考这种聚合模式的起源：它是由前几个后续标记过度信任摘要标记引起的，而惩罚未能纠正它们。因此，一个直观而激进的想法是，如果我们能够排除导致幻觉的标记并在摘要标记之后重新选择正确的前几个标记，则该模式将大大削弱。 回顾分配策略。 当解码过程遇到知识聚合模式并且幻觉不可避免时，它回滚到摘要令牌并选择除了之前选择的候选者之外的其他候选者用于下一个令牌预测。根据经验，解码回顾的条件被设计为对应于几个连续标记的列分数中最大值的位置重叠，其中我们手动将阈值计数设置为r。与不同模型之间变化的最大值不同，位置计数是一个更加稳健和通用的决策指标。 𝟙 手动指定回滚位置 s 必须是单调不递减的。另外，我们配置了回滚的最大时间 3. 论文方法的理论分析或实验评估方法与效果（How） 不同方法、不同模型，在图像级别和句子级别的幻觉表现 对 MSCOCO 数据集（Microsoft COCO，通过收集包含自然环境中常见物体的复杂日常场景的图像来实现的） 进行 CHAIR 评估，该数据集包含超过 300,000 张图像和 80 个带注释的对象。具体来说，我们在验证集中随机选择 500 张图像，并查询不同的 MLLM 模型，并提示“请详细描述该图像”。 不同方法、不同模型，在不同方面的表现（GPT辅助幻觉评估） OPERA确实帮助模型部分克服了由于其偏见或过度信任问题而导致的幻觉问题。我们还注意到，OPERA 以某种方式稍微减少了 MLLM 输出序列的长度，这可能是由于那些额外的幻觉内容的减少所致。 Beam Search和OPERA、不同模型，在正确性和详细性的表现（GPT辅助幻觉评估） 不同方法、不同模型，在随机、流行和对抗性的表现 不同方法，在 LLaVA-1.5 7B 模型上，生成文本质量（语法、流畅度和自然度）的表现（GPT辅助幻觉评估） 不同方法，在流行的 MLLM 基准上的性能的表现 4. 论文优缺点、局限性、借鉴性优点： 之前接触的一些解决幻觉的方法，很多都是通过给模型对应的指令，让其自动调整，而本文却从更为底层的入手 从更为根本的角度揭示了幻觉的出现原因（过度信任） 验证方面做的很全面。 缺点： 图像标注 改进： 假设序列 已经在摘要标记 处呈现了知识聚合模式，我们打算将解码过程回滚到序列手动指定回滚位置 s 必须是单调不递减的 可以稍微向前回滚一点。比如s-k "},{"title":"SAC3：通过语义感知交叉检查一致性在黑盒语言模型中进行可靠的幻觉检测","date":"2024-07-25T16:00:00.000Z","url":"/posts/SAC3-Reliable-Hallucination-Detection/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["大模型安全-幻觉","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8-%E5%B9%BB%E8%A7%89/"]],"categories":[["大模型安全","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"],["幻觉","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E5%B9%BB%E8%A7%89/"]],"content":"1. 研究背景、动机(Why)1.1 研究背景LM 经常表现出一种倾向，即产生极其自信但错误的断言，通常被称为幻觉。这种现象严重阻碍了它们在事实准确性至关重要的领域的适用性。 1.2 存在问题(动机) 不确定性的指标在有限 API 访问的商业黑盒 LM中不可获取：幻觉可以通过捕捉不确定性的指标来检测输出序列。然而，这些指标需要访问令牌级别的日志概率，而这在 ChatGPT 或 Bard 等仅提供有限 API 访问的商业黑盒 LM 中不可用。 1.2.1 现有方案 基于采样的方法，通过建立置信度和自我一致性之间的联系来近似不确定性估计。缺点：自我一致性并不一定能保证事实答案 依赖外部资源，比如从外部数据库检索知识 2. 论文提出的新思路、新理论、或新方法(What) 2.1 第一阶段：通过语义等效扰动进行问题级交叉检查通过生成保留语义等价的替代输入来重新表述输入查询，即语义上等效的输入扰动。 根据查询输入 ,通过提示 “For the question [QUERIED QUESTION], provide k semantically equivalent questions” （“对于问题 [QUERIED QUESTION]，提供 k 个语义等效的问题”） 生成质量过滤。进一步仔细检查生成的输入 和查询的输入之间的语义等价性。 Are the following two inputs semantically equivalent? [QUERIED INPUT] [GENERATED INPUT]” (“以下两个输入在语义上是等价的吗？ [查询的输入] [生成的输入]”)，过滤掉与原始输入不具有相同语义的输入。 2.2 第二阶段：使用附加验证器 LM 进行模型级交叉检查 让 表示来自基于给定查询 的目标 LM 的原始响应。 检测 是​​否出现幻觉。引入了一个额外的验证器 LM，表示为 ，用于模型级交叉检查 两个语言模型 、 分别回答第一阶段生成的 k 个问题的回答定义为 从目标LM的回答中，抽取个样本 从验证LM的回答中，抽取个样本 问题级交叉检查 对于 目标LM生成 个样本响应序列 验证LM生成 个样本响应序列 结合自检和交叉检查中抽取的所有样本。收集总样本集 2.3 第三阶段：一致性分数计算 QA 对的语义感知一致性检查 同一问题的表述方式不同，答案（例如“否”和“是”）在词汇上可能不等效。但 QA 对作为一个整体在语义上可能是等效的 自检一致性分数 表示以两个 QA 对作为输入的语义等价检查运算符 。如果两个 QA 对在语义上等效，则运算符 C 返回“Yes”，否则返回“No”。 利用提示来使用 LM 实现检查运算符：“以下两个问答 (QA) 对在语义上是否等效？[QA 对 1] [QA 对 2] ” 将最佳猜测映射到数值语义等效分数：{“Yes”→ 0.0，“No”→ 1.0} 用 来表示原始 QA 对，目标LM 的自检分数可计算为其中 [!question]在此处是否有必要比较QA对？还是只比较回答就可以？ 问题级一致性分数 模型级一致性分数 模型级交叉检查一致性得分 跨模型跨问题一致性得分 最终得分 λ 是验证者 LM 的权重因子。除非另有说明，在本实验中默认使用 λ = 1 [!question]+是否需要整体除以（1+λ)，或者前者系数为（1-λ）？ 每个组件并行计算 将最终得分与预设阈值进行比较来做出检测预测 3. 论文方法的理论分析或实验评估方法与效果（How）3.1 分类QA任务中的效果50% 幻觉样本和 50% 事实样本情况下，在分类QA任务上比较 SC2 和 SAC3-Q 的表现 100% 幻觉样本、预设阈值 0.5情况下，在分类QA任务上比较 SC2 、SAC3-Q 、、SAC3-all的表现 阈值对检测精度的影响 对于 SC2，很大一部分幻觉样本收到了高度一致的预测 受益于语义等效的问题扰动，SAC3-Q 的分数更加分散在不一致的区域中 3.2 开放域生成QA任务中的效果 信任差异可以通过在验证者 LM 生成的一致性分数中引入权重 λ 来体现。 例如，如果目标是检测特定领域中的幻觉，并且验证器 LM 是为此领域开发的特定领域模型，我们可以为其分数分配较大的权重（例如，λ &gt; 1.0）。一般情况下，验证者LM是小型开源模型，我们可以应用较小的权重值（例如，λ &lt; 1.0）来抵消验证者LM对最终得分的影响。验证者 LM 权重对 AUROC 的影响： 不同 LLM（GPT-3.5、GPT-4 和 PaLM 2）在分类和生成 QA 任务上的准确性。 数据集方面：在分类 QA 和生成 QA上评估幻觉检测方法，每个类别包含两个数据集。 分类QA 素数：该数据集包含 500 个问题，询问 1,000 到 20,000 之间随机选择的素数的素性，其中事实答案始终为“是”。合成的幻觉答案是“不，这不是素数”。 参议员搜索：数据集由 500 个问题组成，遵循以下模板：“是否曾经有一位美国参议员代表 [美国州名] 州，其母校是 [美国大学名称]？”。事实的答案总是“不”。我们还会产生幻觉答案：“是的，有一位美国参议员代表[美国州名]州，他的母校是[美国大学名]。” 生成 QA （手动注释答案的真实性） HotpotQA-halu：利用一个多跳推理的数据集，构建含250 个带有手动注释的非事实和事实示例的数据集 NQ-open-halu：关于自然问题的含 250 个带有手动注释的非事实和事实示例的数据集 实验设置 评估 模型 目标 LM： OpenAI 的 gpt-3.5-turbo 验证器 LM： (1）Falcon-7b-instruct（Almazrouei 等人，2023）：由 TII 构建的开源因果解码器模型，在 RefinedWeb 的 1,500B 代币上进行训练（ Penedo 等人，2023）并使用精选语料库进一步增强； （2）Guanaco-33b：通过 QLoRA（Dettmers 等人，2023）调整 OASST1 数据集上的 LLaMA（Touvron 等人，2023）基本模型的开源指令跟踪模型。 实施细节 在执行语义扰动和一致性检查时，将温度设置为 0.0 以获得确定性的高质量输出。 k = 10 对于基于自检的方法 SC2，将温度设置为 1.0 并生成 ns = 10 个随机样本。 对于 SAC3-Q 和 SAC3-QM ，设置 nq = nqm = 1 以减少计算成本。为了进一步降低推理成本，默认设置 nm = 1 ， 使用幻觉检测精度和 ROC 曲线下面积 (AUROC) 来评估性能。除了估计的幻觉分数之外，我们还显示了目标 LM 的语言概率（Tian et al., 2023）以进行比较。 实验细节 4. 论文优缺点、局限性、借鉴性优点： SAC3方法不依赖于语言模型的内部结构，适用于黑盒语言模型，在实际应用中更为广泛。 考虑到了输入的一致性，检验QA对整体的一致性，而非答案一致性。 改进： 如何增强语义扰动的多样性？ 比如可以完善提示“使用同义词和反义词”、“句式变换”、“改变问题的风格和语调” 交叉检查所带来的效率问题，如何简化交叉检查？（选择最具代表性和关键性的特征进行交叉检查，避免对所有特征都进行全面比对） 该方法的并行只是各个得分计算可以并行。如何设计提示来同时生成多个语义等价的问题变体，如何进行并行的一致性检查 对于频繁出现的问题或类似问题，使用缓存机制存储已生成的问题和其一致性评分，避免重复计算。 论文提到，当验证模型在某一领域表现更好时，可以给它更大的权重。在实际应用中权重的选择，如何实现自动选择一个较优的权重？ 可以通过自动调整机制来确定最优权重，例如使用网格搜索或贝叶斯优化等方法寻找最佳权重值。 "},{"title":"通过自我反思减轻大语言模型中的幻觉","date":"2024-07-18T16:00:00.000Z","url":"/posts/Towards-Mitigating-LLM-Hallucination-via-Self-Reflection/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["大模型安全-幻觉","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8-%E5%B9%BB%E8%A7%89/"]],"categories":[["大模型安全","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"],["幻觉","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E5%B9%BB%E8%A7%89/"]],"content":"1. 研究背景、动机、主要贡献(Why)1.1 研究背景 医疗问答方面 系统能相应各种问题格式 是/否 多选 提取 生成 对医学查询生成流畅且有意义的响应（预训练语言模型的引入） 大语言模型在生成式问答中展现出前景。 1.2 存在问题(动机) “幻觉”问题，即模型生成听起来合理但不忠实或无意义的信息 在医疗领域 幻觉信息可能会对患者护理产生严重后果 不常见的专业概念使医学 GQA 任务变得复杂 目前对LLMs产生的医学答案中幻觉程度的理解仍不明朗 分组查询注意力 (Grouped Query Attention) 是一种在大型语言模型中的多查询注意力 (MQA) 和多头注意力 (MHA) 之间进行插值的方法它的目标是在保持 MQA 速度的同时实现 MHA 的质量。 1.2.1 现有方案 名称 会议名称 年份 方法 Addressing Semantic Drift in Generative Question Answering with Auxiliary Extraction使用辅助提取解决生成问答中的语义漂移 ACL-IJCNLP 2021 2021 在编码器上添加一个提取任务，以获得答案的基本原理，根据提取的基本原理和原始输入，解码器预计会生成高置信度的答案。 Read before Generate! Faithful Long Form Question Answering with Machine Reading在生成之前阅读！通过机器阅读进行忠实的长篇问答 ACL 2022 首先使用检索器从大型外部知识源中搜索相关信息。然后阅读器和生成模块将多个检索到的文档与问题一起作为输入来生成答案。具体来说，阅读器模块采用机器阅读理解（MRC）模型为每个文档中的每个句子生成证据分数，而生成器采用大型预训练的Seq2Seq语言模型，将句子证据分数融合到其生成过程中。 Seq2Seq(Sequence to Sequence)，即序列到序列模型，就是一种能够根据给定的序列，通过特定的生成方法生成另一个序列的方法，同时这两个序列可以不等长。这种结构又叫Encoder-Decoder模型，即编码-解码模型，其是RNN的一个变种，为了解决RNN要求序列等长的问题。 1.3 主要贡献 对医学 GQA 系统中的幻觉现象进行了全面检查。特别是在五个医学 GQA 数据集中应用五个LLMs。 提出了一种交互式自我反思方法，迭代生成答案，直到达到令人满意的水平。 实验结果展示了LLMs无需对特定数据集进行明确培训即可提供有意义的见解的能力。 2. 幻觉分析2.1 模型 Vicuna 通过在 ShareGPT 的用户共享对话上微调 LLaMA 进行训练 AlpacaLoRA 采用低秩适应（LoRA）来复制斯坦福大学 Alpaca 模型的结果 ChatGPT 使用人类反馈强化学习（RLHF）来解释提示并提供全面的响应 MedAlpaca 建立在 LLaMA 框架之上，并在指令调整格式的医学对话和 QA 文本上进行了微调 Robin-medical 使用 LMFlow 在医疗领域微调的 LLaMA 2.2 数据集 PubMedQA 1k 个专家标记的实例 问题来自研究文章的标题 内容来自摘要 长回答来自摘要结论 简洁的yes/no/maybe答案 MedQuAD 包含来自美国国立卫生研究院网站的 47,457 个 QA 对 MEDIQA2019 将挑战赛中得分3和4的答案视为黄金答案 LiveMedQA2017 MASH-QA 包括来自消费者健康领域的 34k QA 对 2.3 结果与讨论问题分类（本文认为前两个是幻觉问题。） 事实不一致 模型回答问题时未能正确回忆相关知识 查询不一致 既没有回答问题也没有适当地调用相关知识 离题 提供与主题相关的信息但不直接解决问题的答案。 模型没有进一步处理掌握的知识（例如归纳、演绎和逻辑推理） 应对这些挑战需要模型能够回忆事实知识、情境理解和推理能力 微调对医学领域的影响 [!note]+ why MedAplpaca 和 Robin-medical 之间的差异表明，指令学习比非指令调整更适合LLMs。 频率的测量 随机选择通用模型生成的 100 个样本 确定问题的关键词或主题，通常是疾病名称 采用 1950-2019 年之间这些关键词的平均频率。（数据来源是Google Ngram Viewer，将其作为自然世界中文本分布和预训练语料库的代理）对于有问题的回答，其关键词的平均频率低于好的回答。低频可能是产生幻觉的潜在原因 3. 缓解幻觉的方法(What) 提出了一个迭代的自我反思过程，该过程利用LLMs生成和完善响应的能力 方法包括三个循环 事实知识获取循环 知识一致回答循环 问题蕴涵回答循环 3.1 事实知识获取循环 模型基于所提供的问题生成背景知识 使用定制的无参考评分器对生成的知识进行事实性评估 Fs(\\mathbf{k}|D,Q)=\\sum_{t=1}^mlogP(k_t|\\mathbf{k_{"},{"title":"嗨！","date":"2024-07-12T16:00:00.000Z","url":"/posts/hello-world/","categories":[["undefined",""]],"content":"哦说声嗨，知道你一定会来"}]