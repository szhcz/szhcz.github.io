[{"title":"An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion","date":"2024-09-20T16:00:00.000Z","url":"/posts/An-Image-is-Worth-One-Word/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["Computer Vision","/tags/Computer-Vision/"],["扩散模型","/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"]],"categories":[["Machine Learning","/categories/Machine-Learning/"],["Computer Vision","/categories/Machine-Learning/Computer-Vision/"]],"content":"1. 研究背景、动机、主要贡献 引入新概念到大模型中往往是困难的。因为重新训练模型非常昂贵，而仅用少量示例进行微调通常会导致“灾难性遗忘”——模型忘记了先前学到的知识。尽管有些方法通过冻结模型并训练转换模块来适应新概念，但这些方法依然面临知识遗忘或无法同时访问新旧概念的难题。 解决方案：文本嵌入空间中的新“词” 1.1 相关工作 1.1.1 文本引导的图像合成 文本引导的图像合成最早是在生成对抗网络（GAN）中研究的。通过给定的图像-文本配对数据集，模型会被训练生成相应的图像。现代的方法引入了注意力机制和跨模态对比方法，以提高生成图像与文本描述的匹配度。 近年来，随着大规模自回归模型和扩散模型的出现，生成图像的质量有了显著提升。这些模型的应用领域不仅限于图像生成，还包括图像编辑、视频合成、运动生成等。 然而，这些方法大多依赖用户通过文本准确描述目标图像的能力。而本文的创新点是引入伪词，扩展了生成模型的词汇量，让模型可以通过新的伪词生成个性化的图像，而无需从头训练模型。 1.1.2 GAN反演 GAN反演是指找到一个潜在表示，使得该潜在向量通过GAN生成与目标图像一致的输出。反演方法通常有两类： - 优化方法：直接优化潜在向量，使之通过GAN生成目标图像。 - 编码器方法：使用大规模数据集训练网络，将图像映射到其潜在表示。 本文采用了优化方法，因为它在处理未见过的新概念时更灵活。而编码器方法在泛化时面临更大挑战，可能需要大规模的网络数据来实现相同的自由度。 1.1.3 扩散模型反演 在扩散模型中，反演可以通过给图像添加噪声，然后利用模型去噪来实现。然而，这种方法往往会显著改变图像内容。改进方法包括通过目标图像的低通滤波数据来指导去噪过程，以及使用闭式反演采样过程，这可以提取一个噪声图并生成相应的图像。 在本文的方法中，作者反演的是用户提供的概念，而不是现有图像，将这些概念表示为模型词汇中的伪词，以便在未来生成过程中用于更广泛和直观的编辑。 1.1.4 个性化 个性化模型一直是机器学习的研究目标，尤其是在推荐系统和联合学习中。 最相关的工作是PALAVRA，该方法利用预训练的CLIP模型检索和分割个性化物体。然而，PALAVRA的任务是判别性的，旨在将物体与其他候选对象区分开来。而本文的方法不仅捕捉到了更多细节，还能实现更自然的图像重建和新场景的合成。 1.2 贡献 提出个性化文本到图像生成任务，生成场景以展示用户提供的特定概念。 在生成模型的背景下提出“文本反演”概念，找到新的伪词嵌入来捕捉高级语义和精细视觉细节。 分析了嵌入空间，展示其在失真与可编辑性之间的权衡，并证明法在这方面表现优越。 通过比较，展示了方法在图像生成的视觉保真度和编辑能力上具有优势。 2. 论文提出的新方法 2.1 LDM 基于LDM实现本方法 2.2 Text embeddings 文本嵌入 文本嵌入是将输入的文本（通常是单词或子词）转换成向量表示的过程。典型的文本编码器模型（如BERT）首先对输入的字符串进行处理，将每个单词或子词转换为token（标记），即某个预定义字典中的索引。 每个token对应于一个唯一的嵌入向量，这个嵌入向量通过索引查找的方式获得。这个嵌入向量表示了该单词或子词在语义空间中的位置，编码了其语义信息。 嵌入向量的学习 文本编码器会在训练过程中学习到这些嵌入向量，使模型可以根据这些向量进行计算和推理，进而理解和生成语言。 嵌入空间逆转 作者选择文本嵌入空间作为逆转目标。具体来说，他们通过引入一个占位符字符串 来表示他们想要学习的新概念。 逆转过程：他们干预嵌入过程，将与token化字符串关联的嵌入向量替换为一个新的、通过优化学习的嵌入向量 。 通过这种方式，模型相当于向词汇表中“注入”了一个新概念，并且可以像使用普通单词一样在生成的句子中使用这个新概念。 2.3 Textual Inversion 文本反演的目标是通过优化从一组图像中学习到的新嵌入向量 ，使得模型能够生成新的视觉概念。作者通过一个小的图像集合（通常是 3-5 张图片）进行直接优化，最终得到一个嵌入向量 ，它能捕捉这个概念的视觉特征。 使用一小组（通常 3-5 张）展示目标概念的图像。这些图像不仅展示了目标物体，还包括不同的背景、姿态等变化。这些变化有助于嵌入向量 捕捉概念的多样性和细节。 通过最小化损失函数（LDM loss）来优化嵌入向量 。让生成的图像尽可能接近输入图像。 优化目标： 在这个过程中，模型保持原本的文本编码器 和去噪网络 不变，只优化嵌入向量 。 为了引导模型生成图像，作者随机采样源自 CLIP ImageNet 模板的中性上下文文本作为文本提示。这些模板包括类似于“A photo of ”或“A rendition of ”的句子，将生成任务与图像内容联系起来，从而为目标概念的嵌入向量 提供上下文。 2.4 Implementation details 保留原始超参数 词嵌入使用一个与目标对象相关的单词（例如“雕塑”或“猫”）的粗略描述来初始化。 实验是在 2 个 NVIDIA V100 GPU 上进行的。这种配置允许进行并行处理，提高了计算效率。使用的批量大小为 4。 基础学习率被设置为 0.005。进一步通过 GPU 数量和批量大小来缩放基本学习率，有效率为 0.04。 所有结果是在 5,000 次优化步骤内生成的。 3. 论文实验评估方法与效果 Image variations Text-guided synthesis Style transfer Concept compositions Bias reduction Downstream applications Image curation 4. 论文局限性 可能仍然难以学习精确的形状，而是融入概念的“语义”本质。 优化时间过长，学习一个概念大约需要两个小时。通过训练编码器直接将一组图像映射到其文本嵌入，这些时间可能会缩短。我们的目标是在未来探索这一领域的工作。 另外，在实验部分作者比较的都是先输入一个小的图像集合（通常是 3-5 张图片）进行优化。本文确实是针对这样一个小的图像集合进行过专门的设计，但是对比的其他模型却没有。这样进行最后生成质量的比较是否有失偏颇？是否应该将图像集合扩大后再进行比较？ 原文链接：An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion"},{"title":"Scalable Diffusion Models with Transformers","date":"2024-09-19T16:00:00.000Z","url":"/posts/Scalable-Diffusion-Models-with-Transformers/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["Computer Vision","/tags/Computer-Vision/"],["扩散模型","/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"]],"categories":[["Machine Learning","/categories/Machine-Learning/"],["Computer Vision","/categories/Machine-Learning/Computer-Vision/"]],"content":"1. 研究背景、动机、主要贡献 传统的扩散模型大多采用U-Net作为主干网络，LDM (High-Resolution Image Synthesis with Latent Diffusion Models) 也只是通过交叉注意力机制增强其底层 UNet 主干网 ，而本文提出的DiT模型替代了U-Net，是使用Transformer来操作图像的潜在表示。 2. 论文提出的新方法 Preliminaries Diffusion formulation. Classifier-free guidance. 条件扩散模型 反向扩散过程变为： 无分类器引导的目标 无分类器引导的主要目的是提升生成结果，使得模型能够生成与给定类别c相关的样本，同时避免直接依赖外部分类器。通过这种引导方式，采样过程会倾向于生成那些与条件信息（类别标签c）高度匹配的样本。 采样过程中的引导 可以利用的梯度来引导模型朝着更符合类别条件 c 的方向生成图像。扩散模型的输出可以被解释为一个得分函数，通过调整生成图像的梯度，来优化生成样本的类别匹配度。 s&gt;1是引导的强度参数，当 s=1时，恢复为标准的采样过程；当 s&gt;1时，引导力度加强，生成图像更倾向于符合类别条件c。 为了避免对外部分类器的依赖，模型会在训练过程中随机丢弃条件 c ，用一个学到的“空”嵌入符号\"null\" 替代。这种方法通过让模型在有和没有条件的情况下都进行学习，从而在测试时能够灵活地处理带条件和不带条件的情况。 Latent diffusion models. Diffusion Transformer Design Space Diffusion Transformer 是一种基于Transformer的扩散模型架构，DiT 保留了 ViT 的许多最佳实践，保持Transformer的可扩展性，特别是用于图像生成任务。 Patchify. DiT的输入是空间表示z，对于256×256×3的图像，z的形状为32×32×4。每个图像被划分为多个小补丁（patch），每个补丁的特征维度是4。 DiT 第一层是“patchify”，它通过线性嵌入将每个补丁转换为一个维度为d的token序列。这一步骤使得模型可以处理输入图像的局部特征。 在patchify之后，DiT使用标准 ViT 基于频率的位置嵌入（sine-cosine version），为所有输入token添加位置信息。 生成的token数量T由补丁大小超参数p决定。如果将p减半，T将增加四倍，从而使 transformer Gflops至少增加四倍。然而，改变p对模型的参数总数没有实质性影响。 在DiT的设计空间中，考虑了p=2、4、8三种补丁大小。 DiT block design. 在 patchify 之后，输入token会通过一系列变换器块进行处理。除了噪声图像输入外，扩散模型还可能处理其他条件信息，如噪声时间步 t 、类别标签 c 、自然语言等。 针对条件输入，本文提出了四种不同的变换器块设计，每种设计对标准ViT块进行了小但重要的修改 上下文条件（In-context conditioning）：将 t 和 c 的向量嵌入作为两个额外的token直接添加到输入序列中，与图像token没有区别。这种方法不需要修改标准的ViT块（类似于 ViT 中的 cls tokens），并在最终块后移除条件token，几乎不增加 Gflops。 交叉注意力块（Cross-attention block）：将 t 和 c 的嵌入合并为一个长度为2的序列，与图像token序列分开。该transformer块在自注意力层之后增加了一个多头交叉注意力层。这种设计会显著增加Gflops，约15%的计算开销。 自适应层归一化块（Adaptive layer norm (adaLN) block）：将标准层归一化替换为adaLN。该层通过对 t 和 c 的嵌入向量的和进行回归，学习维度缩放和偏移参数。与其他块设计相比，adaLN在增加Gflops方面最小，因此在计算上最有效，也是唯一一个对所有token应用相同功能的机制。 adaLN-Zero块：借鉴ResNet的研究，发现将每个残差块初始化为恒等函数是有益的。该设计在adaLN基础上进行修改，在任何残差连接之前也回归维度缩放参数 。初始化多层感知机以对所有 都输出零向量，这会将完整的 DiT 块初始化为恒等函数。这意味着在训练初期，adaLN-Zero块不会对输入施加任何变换。与标准的adaLN块一样，adaLN-Zero 向模型添加了可以忽略不计的 Gflops。 Model size. 使用的一系列 N 个的DiT块，每个块的隐藏维度大小为 d 。 参考 ViT ，作者采用了标准的变换器配置，联合调整 N 、d 和注意力头，以实现不同规模的模型。 作者定义了四种模型配置：DiT-S、DiT-B、DiT-L和DiT-XL。这些配置覆盖了从0.3到118.6 Gflops 的一系列模型规模，使作者能够评估模型的扩展性能。 Transformer decoder. 在经过最后一个DiT块后，模型需要将图像token序列解码为两个输出：一个是噪声预测，另一个是对角协方差预测。这两个输出的形状与原始的空间输入相同。 为了解码这些token，使用了一个标准的线性解码器，将每个token的表示转化为所需的输出形状。 在解码之前，首先应用最后层归一化，（如果使用 adaLN 则为自适应）。 每个token被线性解码为一个形状为 的张量，其中 p 是补丁的大小，C 是 DiT 空间输入中的通道数。 最后，将解码后的tokens重新排列成原始的空间布局，使得模型的输出可以直接用于后续的任务或与原始图像进行比较，以获得预测的噪声和协方差。 3. 论文实验评估方法与效果 DiT块设计 作者训练了四个DiT-XL/2模型，使用不同的块设计（in-context、cross-attention、adaLN、adaLN-zero） adaLN-Zero的初始化方式（将每个DiT块初始化为恒等函数）显著优于普通的adaLN 缩放模型大小和补丁大小 训练了12个DiT模型，变化模型配置（S、B、L、XL）和补丁大小（8、4、2）。 随着模型规模增加和补丁大小减小，FID显著改善。 增大模型的深度和宽度也有助于改进FID。 DiT Gflops 对于提高性能至关重要 参数数量并不是唯一影响模型质量的因素。即使在保持模型规模不变时,总参数实际上没有改变，但是减少补丁大小会导致Gflops增加，从而提高性能。 较大的 DiT 模型的计算效率更高 可视化缩放 在训练400K步骤后，从每个DiT模型中采样图像，使用相同的起始噪声、采样噪声和类别标签，旨在直观地观察模型规模和token数量对生成图像质量的影响。 随着模型规模和处理token数量的增加，生成图像的质量有明显改善。 DiT-XL/2模型在图像生成任务上，相比现有最先进的扩散模型取得了显著的性能提升。 增加采样计算量（如增加采样步数）并不能弥补模型计算量的不足。即便较小的模型通过增加采样步数来提升图像质量，较大的模型仍然能够在更少的计算开销下生成更高质量的图像。 原文链接：Scalable Diffusion Models with Transformers"},{"title":"High-Resolution Image Synthesis with Latent Diffusion Models","date":"2024-09-18T16:00:00.000Z","url":"/posts/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["Computer Vision","/tags/Computer-Vision/"],["扩散模型","/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"]],"categories":[["Machine Learning","/categories/Machine-Learning/"],["Computer Vision","/categories/Machine-Learning/Computer-Vision/"]],"content":"1. 研究背景、动机、主要贡献 传统的扩散模型在像素空间操作，导致计算开销巨大，训练和推理都非常耗时。特别是高分辨率图像合成需要大量的GPU资源，限制了模型的广泛应用。 为了降低计算复杂度，作者提出在预训练的自动编码器的潜在空间中进行扩散模型的训练。使LDM能够在保持视觉细节的同时大大减少计算量。 此外，作者引入了交叉注意力机制，使模型能够进行灵活的条件生成任务，如文本生成图像或边界框生成图像。 主要贡献 比以前的工作提供更忠实和详细的重建 计算复杂度降低 高分辨率图像合成 2. 论文提出的新方法 Perceptual Image Compression 感知压缩模型基于之前的工作，由一个基于感知损失和基于patch的对抗性目标相结合训练的自动编码器组成。与依赖像素级损失（如L2或L1）不同，感知损失和对抗性目标可以确保生成的图像在整体结构和局部细节上都与真实图像一致，从而避免模糊，保持高质量的重建效果。 感知损失（perceptual loss）：感知损失通过衡量重建图像与原始图像在高层次特征空间中的差异，来指导模型生成更逼真的图像。它使用预训练的神经网络（如VGG）提取图像的高层次特征，而不是单纯比较像素级的差异。这样可以更好地保持图像的整体视觉质量和语义一致性。 基于patch的对抗性目标（patch-based adversarial objective）：这是通过生成对抗网络（GAN）来进一步提高图像的局部质量。在这种方法中，判别器会评估图像的局部区域（patch）是否真实，从而迫使生成模型生成更加逼真的局部细节。这种局部对抗性目标可以有效防止重建图像中出现模糊或失真的问题。 自动编码器由编码器和解码器两部分组成。编码器负责将输入的高维图像压缩为低维的潜在表示，解码器则从潜在表示中重建出原始图像。 编码器 对高分辨率图像进行下采样，将其压缩为低维的潜在表示 ，然后解码器 根据潜在表示重建图像 。通过不同的下采样因子，在尽可能减少信息丢失的情况下，压缩图像以减少计算复杂度。 作者为避免潜在空间中出现高方差，采用了两种正则化策略：KL正则化和VQ正则化。通过这两种方法，模型能够更稳定地工作，并且可以在保持图像细节的同时实现较轻的压缩。与之前的将潜在空间表示成一维的自回归方法不同，作者保留了潜在空间的二维结构，这意味着潜在表示保留了空间信息（如图像的高度和宽度），而不是将图像压缩成一维序列。从而更好地保存了图像的空间信息，并且生成效果更加逼真、细腻。 KL正则化（KL-reg.）： 这种方法引入了Kullback-Leibler（KL）散度作为正则化手段。KL散度通常用于衡量两个概率分布之间的差异。在这里，它的作用是将学习到的潜在表示 z 的分布拉近到标准正态分布（mean = 0，variance = 1），类似于变分自编码器（VAE）。 通过在潜在空间上引入KL惩罚，模型可以避免潜在表示的方差过大，保持潜在空间的紧凑性。 VQ正则化（VQ-reg.）： VQ正则化基于向量量化（Vector Quantization, VQ）技术，这种技术在VQ-VAE和VQGAN中广泛应用。它通过离散化潜在空间中的连续表示，使得模型更好地捕捉离散的语义信息。 在这里，VQ层被集成到解码器中，通过将潜在表示限制在特定的离散值上来实现正则化。 VQGAN（Vector Quantized Generative Adversarial Network）是基于VQ的生成模型，作者的设计与VQGAN类似，但VQ层直接融入了解码器结构。 Latent Diffusion Models 相比传统的像素空间，这种低维的潜在空间去除了感知不重要的细节，保留了关键的语义信息，使生成模型能够更加专注于生成重要的图像部分。模型采用UNet架构并通过优化重加权的变分下界，能够在保持高效性的同时生成高质量的图像。 重加权变分下界：在这个模型中，生成过程通过优化一个重加权的变分下界来实现。这种重加权机制允许模型将注意力集中在图像中感知上最重要的部分。损失函数的形式如下： 其中，模型在时间 t 上根据潜在表示 进行去噪。 时间条件的UNet：模型的主干是一个时间条件的UNet。UNet是一种适合图像生成的神经网络架构，通过卷积操作捕捉图像的局部特征，并逐步恢复图像细节。在这个模型中，UNet根据输入的噪声和时间步 t 进行去噪。 在训练时，前向过程是固定的。一旦潜在表示 通过编码器 E 得到，模型可以通过单次通过解码器 D 将潜在表示解码回图像。这种高效的推理过程使得生成图像更加快速。 Conditioning Mechanisms 扩散模型可以通过引入条件输入来进行灵活的图像生成。本文的方法通过交叉注意力机制结合不同模态的输入（如文本、语义图等），并使用特定领域编码器 处理这些输入。这种方法使得扩散模型不仅能够生成高质量图像，还能根据输入的条件对生成结果进行精确控制。训练过程中，去噪自编码器和条件编码器是联合优化的，从而确保模型能够同时学习如何去噪和如何从条件中提取信息。这种机制的灵活性使得模型能够适应多种生成任务。 条件生成模型 条件分布 p(z∣y)：扩散模型可以建模条件分布 p(z∣y)。条件生成意味着模型可以通过给定的输入条件来生成特定的输出。例如，给定某个文本描述，模型可以生成与该描述相关的图像。 条件去噪自编码器 ：噪声输入 、时间步 t，还引入条件信息 y。通过条件去噪自编码器，模型能够在去噪过程中利用 y 来指导生成的方向。y 可以是文本、语义地图、或者其他形式的条件输入。 Beyond Class Labels 以往的扩散模型主要通过类别标签（class labels）或者模糊图像变体（blurred variants of the input image）进行条件生成。然而，将扩散模型与其他条件输入形式结合，目前仍然是一个研究较少的领域。 本文提出将扩散模型与交叉注意力机制（cross-attention mechanism）结合，扩展了模型的条件生成能力。 交叉注意力机制 UNet架构中的交叉注意力：通过交叉注意力机制增强其底层 UNet 主干网。具体地，通过交叉注意力层来处理多种输入模态（如语言提示），从而使模型在不同的输入条件下生成相应的图像。 处理条件输入 y 为了处理不同类型的条件输入 y（如文本、图像或语义图），模型引入了一个特定领域编码器 。该编码器将输入 y 投射到一个中间表示 ，表示为维度为 Missing superscript or subscript argumentMd_ 的矩阵。 通过交叉注意力机制，模型能够将条件输入 y 的中间表示用 传递给UNet的中间层。具体的注意力机制计算如下： Q 是对UNet中间表示 进行线性变换后的查询矩阵。 K 和 V 是通过将条件输入 进行线性变换后的键和值矩阵。 注意力机制通过对 Q 和 K 的点积进行加权，从 V 中提取相关信息，从而在生成过程中融入条件信息。 条件扩散模型的训练 损失函数变为： 损失函数衡量模型预测的去噪结果 与真实的噪声 之间的差异。 和 是联合优化的，所以模型不仅学习去噪的过程，还学习如何从条件输入中提取有用信息。 可以由特定领域的专家进行参数化 3. 论文方法的理论分析或实验评估方法与效果 3.1 感知压缩的权衡分析 探讨不同下采样因子 f 对模型生成质量和计算效率的影响，分别在 进行实验。 较小的压缩因子（如 LDM-1）需要更多的训练时间，而较大的压缩因子（如 LDM-32）虽然计算效率高，但生成的图像质量较差。适中的压缩因子（如 LDM-4 到 LDM-16）在计算效率和图像质量之间达到了良好的平衡 。 3.2 无条件图像生成 在 CelebA-HQ、FFHQ、LSUN-Churches 和 ImageNet 数据集上训练了无条件生成模型，图像分辨率为 256x256。 LDM-4 模型在 CelebA-HQ 数据集上达到了新的最优 FID 分数，在生成质量上超越了GAN和VAE等方法 。 3.3 文本条件生成 在 MS-COCO 数据集上测试文本条件生成，使用交叉注意力机制将文本提示与生成图像关联。 LDM 模型在文本条件生成任务中的表现优于其他基于自回归模型的生成方法，如 DALL-E 和 CogView，在 FID 和生成多样性方面具有优势 。 3.4 超分辨率与图像修复 超分辨率：LDM 模型在 ImageNet 数据集上进行了 64x64 到 256x256 的超分辨率生成实验，生成的图像细节更为逼真。 图像修复：在 Places 数据集上进行了图像修复实验（inpainting），特别是对图像中 40-50% 被遮挡区域进行修复。 4. 论文创新点 将潜在扩散模型应用于低维潜在空间 降低了计算复杂度，并且通过感知压缩模型去除不重要的高频细节，从而在保持高生成质量的前提下实现高效的图像合成。 引入交叉注意力机制进行灵活的条件生成 引入领域特定编码器来处理不同类型的输入，并通过交叉注意力将这些条件输入的信息注入到生成过程中。 在潜在空间中进行多模态生成的灵活性 不同于以往依赖自回归或离散潜在空间的生成模型，该方法在潜在扩散模型中保留了图像的二维空间结构。这使得模型可以处理更加丰富的输入信息（如语义图、语言提示等），而不是将图像压缩成一维的离散序列。 原文链接：High-Resolution Image Synthesis with Latent Diffusion Models"},{"title":"DENOISING DIFFUSION IMPLICIT MODELS","date":"2024-09-17T16:00:00.000Z","url":"/posts/DENOISING-DIFFUSION-IMPLICIT-MODELS/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["Computer Vision","/tags/Computer-Vision/"],["扩散模型","/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"]],"categories":[["Machine Learning","/categories/Machine-Learning/"],["Computer Vision","/categories/Machine-Learning/Computer-Vision/"]],"content":"1. 研究背景、动机、主要贡献 在 DDPM 中，生成过程被定义为特定马尔可夫扩散过程的逆过程。 本方法通过一类非马尔可夫扩散过程来推广 DDPM。 这些非马尔可夫过程可以对应于确定性的生成过程，从而产生能够更快地生成高质量样本的隐式模型。 2. 论文提出的新方法 VARIATIONAL INFERENCE FOR NON-MARKOVIAN FORWARD PROCESSES DDPM 论文中： , , 本文（DDIM)： , ,(利用 的不同，不断代换就能得出) ， 根据 ， （) SAMPLING FROM GENERALIZED GENERATIVE PROCESSES DENOISING DIFFUSION IMPLICIT MODELS 当 ，给定 和 ，前向过程变得确定性，t = 1 时除外。因此想求 ,不一定要求出 我们将其命名为去噪扩散隐式模型，因为它是使用 DDPM 目标训练的隐式概率模型（尽管前向过程不再是扩散）。 ACCELERATED GENERATION PROCESSES DDLM是利用马尔可夫过程，所以要依赖前面的状态。但是本方法不依赖前面的状态，就可以加速。 此外，本文是在 Improved Denoising Diffusion Probabilistic Models 基础上实现的加速（引入子序列进行采样） 3. 论文实验评估方法与效果 随着时间步数的增加，样本质量提高。 DDIM（η=0）在较短的步数下就能得到比较好的效果，媲美DDPM（η=1）的生成效果。 DDIM 能够在 20 到 100 个步骤内生成质量与 1000 个步骤模型相当的样本，与原始 DDPM 相比，速度提高了 10 到 50 倍。 原文链接：DENOISING DIFFUSION IMPLICIT MODELS"},{"title":"Improved Denoising Diffusion Probabilistic Models","date":"2024-09-15T16:00:00.000Z","url":"/posts/Improved-Denoising-Diffusion-Probabilistic-Models/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["Computer Vision","/tags/Computer-Vision/"],["扩散模型","/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"]],"categories":[["Machine Learning","/categories/Machine-Learning/"],["Computer Vision","/categories/Machine-Learning/Computer-Vision/"]],"content":"1. 研究背景、动机、主要贡献 DDPM的论文有指出与其他基于似然的模型相比，我们的模型不具有竞争性的对数似然。 而本文主要做的两件事情就是提高对数似然和提高采样速度。 本文还发现，DDPM 可以与 GAN 的样本质量相匹配，同时根据召回率衡量，可以实现更好的模式覆盖率。 本文还研究了 DDPM 如何随着可用训练计算量的变化而扩展，并发现更多的训练计算会带来更好的样本质量和对数似然。 2. 论文提出的新思路或新方法 2.1 提高对数似然 2.1.1 Learning （将方差参数化为 和 之间的插值） 在DDPM中，相对于方差，更多关注的是分布的均值。且利用均值相等作为条件，来推导出噪音的权重。 本文从 DDPM 中方差的设置入手（ ，将 固定为 与将其固定为 的样本质量大致相同）。但也发现，随着增加扩散步骤的数量， 和 在更多的扩散过程中保持彼此接近。得出在扩散步骤较大时，模型均值更能决定分布。 固定方差似乎是一个合理的选择，但它没有提到对数似然。事实上，显示扩散过程的前几个步骤对变分下界的贡献最大。因此，可以通过使用更好的 选择来提高对数似然。 本文是将方差参数化为 和 之间的插值。模型输出一个向量 v，每个维度包含一个分量。（不对 v 做约束，但是实践中模型却并没有预测插值范围之外的方差） 2.1.2 Improving the Noise Schedule （重新构建噪声表，使 随着扩散步骤增加，下降更平缓，降低信息破坏的速度） Ho 等人使用的线性噪声表对于高分辨率图像效果很好，但对于分辨率 64 × 64 和 32 × 32 的图像来说效果不佳。 线性计划最后四分之一的潜伏几乎纯粹是噪声，而余弦计划增加噪声的速度更慢 当跳过高达20%的反向扩散过程时，用线性时间表训练的模型不会变得更糟（通过FID测量）。（就存在较多的无效时间） 因此，重新构建噪声表 将 限制为不大于 0.999，以防止在扩散过程结束时接近 t = T 时出现奇点。 余弦时间表设计为在过程中间有一个 的线性下降，同时在 t = 0 和 t = T 的极值附近变化很小，以防止噪声水平突然变化。 使用较小的偏移量 s 来防止 在 t = 0 附近太小，因为在过程开始时存在少量噪声会使网络难以足够准确地进行预测。选择 s= 0.008 使得 略小于像素箱大小 1/127.5。 选择使用 ，因为它是一个常见的数学函数，具有我们正在寻找的形状。 图 5 可以看到 Ho 等人的线性时间表下降到零的速度要快得多，信息破坏的速度比必要的要快。 2.1.3 Reducing Gradient Noise （重要性采样） ，因此希望通过直接优化 而不是通过优化 来实现最佳对数似然。然而， 在实践中实际上很难优化(至少在多样化的 ImageNet 64 × 64 数据集上是这样) 的梯度比 的梯度大很多 注意到 的不同项具有区别很大的不同大小，假设均匀采样 t 会在 目标中产生不必要的噪声。为了解决这个问题，我们采用重要性采样： 由于 事先未知，并且在整个训练过程中可能会发生变化，因此维护每个损失项的前 10 个值的历史记录，并在训练期间动态更新。 2.2 Improving Sampling Speed 所有的模型都经过 4000 个扩散步骤的训练，在现代 GPU 上生成单个样本需要几分钟的时间，但本文的方法使得我们可以在几秒钟而不是几分钟内从我们的模型中进行采样。 对于使用 T 个扩散步骤训练的模型，我们通常会使用与训练期间使用的相同的 t 值序列 (1, 2, ..., T ) 进行采样。本文使用 t 值的任意子序列 S 进行采样。给定训练噪声表 ，对于给定的序列 S，得到采样噪声表 ，相应的采样方差为 为了将采样步骤数从 T 减少到 K，使用 1 到 T（含）之间的 K 个均匀间隔的实数，然后将每个结果数字舍入到最接近的整数。 使用此模型，100 个采样步骤足以为完全训练的模型实现接近最佳的 FID 2.3 Scaling Model Size 为了衡量性能如何随着训练计算而扩展，使用 Lhybrid 目标在 ImageNet 64 × 64 上训练四个不同的模型。 为了改变模型容量，我们在所有层上应用深度乘数，使得第一层具有 64、96、128 或 192 个通道。(之前的实验在第一层使用了 128 个通道。) 由于每层的深度都会影响初始权重的规模，因此我们将每个模型的 Adam 学习率缩放为 ，使得 128 通道模型的学习率为 0.0001 (正如其他实验一样）。 原文链接：Improved Denoising Diffusion Probabilistic Models"},{"title":"Denoising Diffusion Probabilistic Models","date":"2024-09-14T16:00:00.000Z","url":"/posts/Denoising-Diffusion-Probabilistic-Models/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["Computer Vision","/tags/Computer-Vision/"],["扩散模型","/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"]],"categories":[["Machine Learning","/categories/Machine-Learning/"],["Computer Vision","/categories/Machine-Learning/Computer-Vision/"]],"content":"1. 扩散模型和去噪自动编码器 方法原理 方法原理大概就是对于 Noise Predicter 输入一张有噪音的图、当前的步骤编号（和文字提示），然后 Noise Predicter 生成预测的噪音，再用原来的图片减去噪音，得到更完整的图片。不断迭代。 而 Noise Predicter 的训练资料就是对于完整的图片，不断加入噪音 文字到图片主要就是文字先经过一个好的 Text Encoder ，生成向量，在加入噪音，生成模型就生成中间产物，中间产物图片压缩版本经过Decoder生成最终图片 公式推导 实际上并不是一步一步地去噪音的，每一个循环都是在尽量找出对应的噪音，希望能够最大地去噪。 首先是尝试找到 值，使模型生成的network生成 概率最大 可能无法找到 的最大值，所以会希望它的下界最大。 最终可以化简为（要使下面的式子最小） 要使 最小，希望两个分布的mean最接近。 根据 ，替换 ,得到 需要在 的条件下预测为 。 实际上就是需要预测 2. 实验评估方法与效果 为所有实验设置 T = 1000，将前向过程方差设置为从 线性增加到 的常数。这些常数相对于缩放至 [−1, 1] 的数据较小，确保反向和正向过程具有大致相同的函数形式，同时保持 处的信噪比尽可能小 。为了表示相反的过程，使用类似于未屏蔽的 PixelCNN++ 的 U-Net 主干网，并始终进行group normalization。参数是跨时间共享的，这是使用 Transformer 正弦位置嵌入指定给网络的。在 16 × 16 特征图分辨率下使用自注意力。 原文链接：Denoising Diffusion Probabilistic Models"},{"title":"OPERA：通过过度信任惩罚和回顾分配减轻多模态大语言模型中的幻觉","date":"2024-08-15T16:00:00.000Z","url":"/posts/OPERA-Alleviating-Hallucination-in-Multi-Modal-Large-Language-Models/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["大模型安全-幻觉","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8-%E5%B9%BB%E8%A7%89/"]],"categories":[["大模型安全","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"],["幻觉","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E5%B9%BB%E8%A7%89/"]],"content":"1. 研究背景、动机、主要贡献(Why)1.1 研究背景最近多模态大语言模型的发展使基础模型能够让用户使用图像作为输入进行交互。MLLM 的能力使其能够胜任各种视觉任务。 MLLM 也面临着“幻觉”问题。例如，产生不相关或无意义的响应，识别图像中不存在的颜色、数量和位置方面不准确的对象。这一缺陷给 MLLM 成为值得信赖的助手的实际应用带来了巨大的风险。例如，在模型辅助自动驾驶场景中，这种对道路场景图像的误解可能会导致系统的错误判断并导致严重的交通事故。 1.2 存在问题(动机)1.2.1 现有方案缺点 方法会产生大量的额外成本，包括用于训练的额外指令数据的注释预算、外部知识或模型的集成 1.3 主要贡献 无需引入任何外部数据、知识或额外的培训。 我们揭示了幻觉和过度信任模式的出现，并提出了一种配备回顾重新分配策略的基于惩罚的解码方法。 包括GPT 评估在内的广泛评估证明了OPERA 的卓越性能，它几乎可以作为缓解幻觉的免费午餐。 2. 论文提出的新方法(What)2.1 制定 MLLM 的生成过程2.1.1 输入构造MLLM 的输入包含 图像 MLLM 通常使用视觉编码器从原始图像中提取视觉标记 将视觉标记表示为 。这里N是视觉标记的长度，在大多数情况下它是固定的数字 并使用跨模态映射模块将它们映射到 LLM 的输入空间。 文本。 输入文本使用分词器进行分词 将其表示为。 图像和文本标记连接起来作为最终的输入序列，我们将其表示为， T = N + M 。 2.1.2 模型前向传播 MLLM 使用因果注意掩码以自回归方式进行训练，每个标记根据先前的标记预测其下一个标记。 Causal Mask 主要用于限定模型的可视范围，防止模型看到未来的数据。 h 是 MLLM 最后一层的输出隐藏状态，包含了模型对输入序列的编码和理解 e.g. 假设有一个 MLLM 模型，输入一个句子 \"The weather is nice today.\"，模型经过处理后会有一个隐藏状态 “h”，这个隐藏状态包含了模型对整个句子的编码表示。 假设 “h” 是一个包含 512 维度的向量，其中每个维度可能对应于句子中的不同语义特征。 MLLM 使用词汇头 来投影隐藏状态 h 并获取下一个标记预测的 logits（或概率） e.g. 词汇头，通常是指用于将隐藏状态映射为词汇表中每个单词的概率分布的神经网络层。这个层通常是一个全连接层，其输出是一个向量，每个元素对应于词汇表中一个单词的概率。这个输出向量可以通过 softmax 函数转换为概率分布，用于生成下一个可能的标记。 假设我们有一个掩码语言模型（MLLM），输入是一个经过编码后的序列的隐藏状态 “h”，我们想要预测下一个单词。 假设我们的词汇表中有以下单词：[“speak”, “I”, “Chinese”, “can”]。 现在，我们将隐藏状态 “h” 经过词汇头的处理，得到一个包含四个元素的向量，分别对应于词汇表中的每个单词。这个向量可以表示为 [0.1, 0.6, 0.2, 0.1]。 通过 softmax 函数，我们可以将这个向量转换为概率分布。经过 softmax 处理后，我们得到的概率分布如下所示： “speak”: “I”: “Chinese”: “can”: 2.1.3 解码OPERA 基于 Beam Search这是一种基于累积分数的解码策略。简而言之，对于给定的束大小，束搜索保留候选序列，其中每个候选序列都是带有波束分数的解码序列。当解码 token 时，每个候选假设将根据 logits 中的 Top-概率选择 候选 token。最后，解码过程将输出假设赢得最佳波束分数。 e.g. 2.2 过度信任惩罚2.2.1 前置背景在浅层中，标签词从演示中收集信息以形成语义表示以进行更深入的处理，而深层则从标签词中提取并利用这些信息来制定最终预测。 可视化自注意力图。 非对角线元素表示模型在生成当前输出标记时对其他输入位置的关注程度。 柱状注意力模式通常表现在缺乏大量信息的标记上，例如句号或引号。 柱状注意力模式的令牌通常拥有有限的信息，但却对所有后续令牌的预测产生显着影响。 (a) 聚合模式与最近的“锚定令牌”观察结果一致。 (b)、(c) 显示当上下文中出现更多锚标记时，5,000 张随机选择的 MSCOCO 图像上的 CHAIR 分数（更多幻觉）不断增加。 知识聚合后面的内容大部分都带有推理或者幻觉 2.2.2 具体方法幻觉和知识聚合模式之间存在高概率的共存。然而，这种模式具有显着的滞后性，即，当对应的令牌被解码时，不能立即观察到模式，而是在后续的几个令牌被解码之后，幻觉可能已经发生。为了应对滞后现象，我们提出了“过度信任惩罚”。 当前生成的序列 下一个标志词预测的因果自注意力权重causual self-attention weights 考虑在局部窗口中收集所有先前的自注意力权重来表征知识模式，即局部窗口注意力定义为 其中 k 表示我们在注意力图上裁剪的局部窗口的大小，表示第 j 个标记分配给第 i 个标记的注意力权重 预处理，用零填充矩阵的上三角形并放大注意力值其中为零，σ 是可配置的比例因子。 对注意力矩阵的下三角进行列乘法，并获得列分数向量。直观上，分数越大表示相应位置存在的模式越强。因此，我们选择列向得分向量的最大值作为知识聚合模式的特征。 2.3 回顾-分配策略通常，惩罚项能够惩罚具有知识聚合模式的候选者，并鼓励其他候选者被预测。但也有少数情况是，所有候选者都受到惩罚，而幻觉已经出现。 这个案例促使我们重新思考这种聚合模式的起源：它是由前几个后续标记过度信任摘要标记引起的，而惩罚未能纠正它们。因此，一个直观而激进的想法是，如果我们能够排除导致幻觉的标记并在摘要标记之后重新选择正确的前几个标记，则该模式将大大削弱。 回顾分配策略。 当解码过程遇到知识聚合模式并且幻觉不可避免时，它回滚到摘要令牌并选择除了之前选择的候选者之外的其他候选者用于下一个令牌预测。根据经验，解码回顾的条件被设计为对应于几个连续标记的列分数中最大值的位置重叠，其中我们手动将阈值计数设置为r。与不同模型之间变化的最大值不同，位置计数是一个更加稳健和通用的决策指标。 𝟙 手动指定回滚位置 s 必须是单调不递减的。另外，我们配置了回滚的最大时间 3. 论文方法的理论分析或实验评估方法与效果（How） 不同方法、不同模型，在图像级别和句子级别的幻觉表现 对 MSCOCO 数据集（Microsoft COCO，通过收集包含自然环境中常见物体的复杂日常场景的图像来实现的） 进行 CHAIR 评估，该数据集包含超过 300,000 张图像和 80 个带注释的对象。具体来说，我们在验证集中随机选择 500 张图像，并查询不同的 MLLM 模型，并提示“请详细描述该图像”。 不同方法、不同模型，在不同方面的表现（GPT辅助幻觉评估） OPERA确实帮助模型部分克服了由于其偏见或过度信任问题而导致的幻觉问题。我们还注意到，OPERA 以某种方式稍微减少了 MLLM 输出序列的长度，这可能是由于那些额外的幻觉内容的减少所致。 Beam Search和OPERA、不同模型，在正确性和详细性的表现（GPT辅助幻觉评估） 不同方法、不同模型，在随机、流行和对抗性的表现 不同方法，在 LLaVA-1.5 7B 模型上，生成文本质量（语法、流畅度和自然度）的表现（GPT辅助幻觉评估） 不同方法，在流行的 MLLM 基准上的性能的表现 4. 论文优缺点、局限性、借鉴性优点： 之前接触的一些解决幻觉的方法，很多都是通过给模型对应的指令，让其自动调整，而本文却从更为底层的入手 从更为根本的角度揭示了幻觉的出现原因（过度信任） 验证方面做的很全面。 缺点： 图像标注 改进： 假设序列 已经在摘要标记 处呈现了知识聚合模式，我们打算将解码过程回滚到序列手动指定回滚位置 s 必须是单调不递减的 可以稍微向前回滚一点。比如s-k "},{"title":"SAC3：通过语义感知交叉检查一致性在黑盒语言模型中进行可靠的幻觉检测","date":"2024-07-25T16:00:00.000Z","url":"/posts/SAC3-Reliable-Hallucination-Detection/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["大模型安全-幻觉","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8-%E5%B9%BB%E8%A7%89/"]],"categories":[["大模型安全","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"],["幻觉","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E5%B9%BB%E8%A7%89/"]],"content":"1. 研究背景、动机(Why) 1.1 研究背景 LM 经常表现出一种倾向，即产生极其自信但错误的断言，通常被称为幻觉。这种现象严重阻碍了它们在事实准确性至关重要的领域的适用性。 1.2 存在问题(动机) 不确定性的指标在有限 API 访问的商业黑盒 LM中不可获取：幻觉可以通过捕捉不确定性的指标来检测输出序列。然而，这些指标需要访问令牌级别的日志概率，而这在 ChatGPT 或 Bard 等仅提供有限 API 访问的商业黑盒 LM 中不可用。 1.2.1 现有方案 基于采样的方法，通过建立置信度和自我一致性之间的联系来近似不确定性估计。 缺点：自我一致性并不一定能保证事实答案 依赖外部资源，比如从外部数据库检索知识 2. 论文提出的新思路、新理论、或新方法(What) 2.1 第一阶段：通过语义等效扰动进行问题级交叉检查 通过生成保留语义等价的替代输入来重新表述输入查询，即语义上等效的输入扰动。 1. 根据查询输入 ,通过提示 “For the question [QUERIED QUESTION], provide k semantically equivalent questions” （“对于问题 [QUERIED QUESTION]，提供 k 个语义等效的问题”） 2. 生成质量过滤。进一步仔细检查生成的输入 和查询的输入之间的语义等价性。 Are the following two inputs semantically equivalent? [QUERIED INPUT] [GENERATED INPUT]” (“以下两个输入在语义上是等价的吗？ [查询的输入] [生成的输入]”)，过滤掉与原始输入不具有相同语义的输入。 2.2 第二阶段：使用附加验证器 LM 进行模型级交叉检查 让 表示来自基于给定查询 的目标 LM 的原始响应。 检测 是​​否出现幻觉。引入了一个额外的验证器 LM，表示为 ，用于模型级交叉检查 两个语言模型 、 分别回答第一阶段生成的 k 个问题的回答定义为 从目标LM的回答中，抽取个样本 从验证LM的回答中，抽取个样本 问题级交叉检查 对于 目标LM生成 个样本响应序列 验证LM生成 个样本响应序列 结合自检和交叉检查中抽取的所有样本。收集总样本集 2.3 第三阶段：一致性分数计算 QA 对的语义感知一致性检查 同一问题的表述方式不同，答案（例如“否”和“是”）在词汇上可能不等效。但 QA 对作为一个整体在语义上可能是等效的 自检一致性分数 表示以两个 QA 对作为输入的语义等价检查运算符 。如果两个 QA 对在语义上等效，则运算符 C 返回“Yes”，否则返回“No”。 利用提示来使用 LM 实现检查运算符：“以下两个问答 (QA) 对在语义上是否等效？[QA 对 1] [QA 对 2] ” 将最佳猜测映射到数值语义等效分数：{“Yes”→ 0.0，“No”→ 1.0} 用 来表示原始 QA 对，目标LM 的自检分数可计算为其中 &gt;[!question] &gt;在此处是否有必要比较QA对？还是只比较回答就可以？ 问题级一致性分数 模型级一致性分数 模型级交叉检查一致性得分 跨模型跨问题一致性得分 最终得分 λ 是验证者 LM 的权重因子。除非另有说明，在本实验中默认使用 λ = 1 &gt;[!question]+ &gt;是否需要整体除以（1+λ)，或者前者系数为（1-λ）？ 每个组件并行计算 将最终得分与预设阈值进行比较来做出检测预测 3. 论文方法的理论分析或实验评估方法与效果（How） 3.1 分类QA任务中的效果 50% 幻觉样本和 50% 事实样本情况下，在分类QA任务上比较 SC2 和 SAC3-Q 的表现 100% 幻觉样本、预设阈值 0.5情况下，在分类QA任务上比较 SC2 、SAC3-Q 、、SAC3-all的表现 阈值对检测精度的影响 对于 SC2，很大一部分幻觉样本收到了高度一致的预测 受益于语义等效的问题扰动，SAC3-Q 的分数更加分散在不一致的区域中 3.2 开放域生成QA任务中的效果 AUROC 关于开放域生成 QA 任务 信任差异可以通过在验证者 LM 生成的一致性分数中引入权重 λ 来体现。 例如，如果目标是检测特定领域中的幻觉，并且验证器 LM 是为此领域开发的特定领域模型，我们可以为其分数分配较大的权重（例如，λ &gt; 1.0）。一般情况下，验证者LM是小型开源模型，我们可以应用较小的权重值（例如，λ &lt; 1.0）来抵消验证者LM对最终得分的影响。 验证者 LM 权重对 AUROC 的影响： 不同 LLM（GPT-3.5、GPT-4 和 PaLM 2）在分类和生成 QA 任务上的准确性。 数据集方面：在分类 QA 和生成 QA上评估幻觉检测方法，每个类别包含两个数据集。 分类QA 素数：该数据集包含 500 个问题，询问 1,000 到 20,000 之间随机选择的素数的素性，其中事实答案始终为“是”。合成的幻觉答案是“不，这不是素数”。 参议员搜索：数据集由 500 个问题组成，遵循以下模板：“是否曾经有一位美国参议员代表 [美国州名] 州，其母校是 [美国大学名称]？”。事实的答案总是“不”。我们还会产生幻觉答案：“是的，有一位美国参议员代表[美国州名]州，他的母校是[美国大学名]。” 生成 QA （手动注释答案的真实性） HotpotQA-halu：利用一个多跳推理的数据集，构建含250 个带有手动注释的非事实和事实示例的数据集 NQ-open-halu：关于自然问题的含 250 个带有手动注释的非事实和事实示例的数据集 实验设置 评估 模型 目标 LM： OpenAI 的 gpt-3.5-turbo 验证器 LM： (1）Falcon-7b-instruct（Almazrouei 等人，2023）：由 TII 构建的开源因果解码器模型，在 RefinedWeb 的 1,500B 代币上进行训练（ Penedo 等人，2023）并使用精选语料库进一步增强； （2）Guanaco-33b：通过 QLoRA（Dettmers 等人，2023）调整 OASST1 数据集上的 LLaMA（Touvron 等人，2023）基本模型的开源指令跟踪模型。 实施细节 在执行语义扰动和一致性检查时，将温度设置为 0.0 以获得确定性的高质量输出。 k = 10 对于基于自检的方法 SC2，将温度设置为 1.0 并生成 ns = 10 个随机样本。 对于 SAC3-Q 和 SAC3-QM ，设置 nq = nqm = 1 以减少计算成本。为了进一步降低推理成本，默认设置 nm = 1 ， 使用幻觉检测精度和 ROC 曲线下面积 (AUROC) 来评估性能。除了估计的幻觉分数之外，我们还显示了目标 LM 的语言概率（Tian et al., 2023）以进行比较。 实验细节 4. 论文优缺点、局限性、借鉴性 优点： SAC3方法不依赖于语言模型的内部结构，适用于黑盒语言模型，在实际应用中更为广泛。 考虑到了输入的一致性，检验QA对整体的一致性，而非答案一致性。 改进： 如何增强语义扰动的多样性？ 比如可以完善提示“使用同义词和反义词”、“句式变换”、“改变问题的风格和语调” 交叉检查所带来的效率问题，如何简化交叉检查？（选择最具代表性和关键性的特征进行交叉检查，避免对所有特征都进行全面比对） 该方法的并行只是各个得分计算可以并行。如何设计提示来同时生成多个语义等价的问题变体，如何进行并行的一致性检查 对于频繁出现的问题或类似问题，使用缓存机制存储已生成的问题和其一致性评分，避免重复计算。 论文提到，当验证模型在某一领域表现更好时，可以给它更大的权重。在实际应用中权重的选择，如何实现自动选择一个较优的权重？ 可以通过自动调整机制来确定最优权重，例如使用网格搜索或贝叶斯优化等方法寻找最佳权重值。 "},{"title":"通过自我反思减轻大语言模型中的幻觉","date":"2024-07-18T16:00:00.000Z","url":"/posts/Towards-Mitigating-LLM-Hallucination-via-Self-Reflection/","tags":[["论文阅读","/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"],["大模型安全-幻觉","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8-%E5%B9%BB%E8%A7%89/"]],"categories":[["大模型安全","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/"],["幻觉","/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E5%B9%BB%E8%A7%89/"]],"content":"1. 研究背景、动机、主要贡献(Why)1.1 研究背景 医疗问答方面 系统能相应各种问题格式 是/否 多选 提取 生成 对医学查询生成流畅且有意义的响应（预训练语言模型的引入） 大语言模型在生成式问答中展现出前景。 1.2 存在问题(动机) “幻觉”问题，即模型生成听起来合理但不忠实或无意义的信息 在医疗领域 幻觉信息可能会对患者护理产生严重后果 不常见的专业概念使医学 GQA 任务变得复杂 目前对LLMs产生的医学答案中幻觉程度的理解仍不明朗 分组查询注意力 (Grouped Query Attention) 是一种在大型语言模型中的多查询注意力 (MQA) 和多头注意力 (MHA) 之间进行插值的方法它的目标是在保持 MQA 速度的同时实现 MHA 的质量。 1.2.1 现有方案 名称 会议名称 年份 方法 Addressing Semantic Drift in Generative Question Answering with Auxiliary Extraction使用辅助提取解决生成问答中的语义漂移 ACL-IJCNLP 2021 2021 在编码器上添加一个提取任务，以获得答案的基本原理，根据提取的基本原理和原始输入，解码器预计会生成高置信度的答案。 Read before Generate! Faithful Long Form Question Answering with Machine Reading在生成之前阅读！通过机器阅读进行忠实的长篇问答 ACL 2022 首先使用检索器从大型外部知识源中搜索相关信息。然后阅读器和生成模块将多个检索到的文档与问题一起作为输入来生成答案。具体来说，阅读器模块采用机器阅读理解（MRC）模型为每个文档中的每个句子生成证据分数，而生成器采用大型预训练的Seq2Seq语言模型，将句子证据分数融合到其生成过程中。 Seq2Seq(Sequence to Sequence)，即序列到序列模型，就是一种能够根据给定的序列，通过特定的生成方法生成另一个序列的方法，同时这两个序列可以不等长。这种结构又叫Encoder-Decoder模型，即编码-解码模型，其是RNN的一个变种，为了解决RNN要求序列等长的问题。 1.3 主要贡献 对医学 GQA 系统中的幻觉现象进行了全面检查。特别是在五个医学 GQA 数据集中应用五个LLMs。 提出了一种交互式自我反思方法，迭代生成答案，直到达到令人满意的水平。 实验结果展示了LLMs无需对特定数据集进行明确培训即可提供有意义的见解的能力。 2. 幻觉分析2.1 模型 Vicuna 通过在 ShareGPT 的用户共享对话上微调 LLaMA 进行训练 AlpacaLoRA 采用低秩适应（LoRA）来复制斯坦福大学 Alpaca 模型的结果 ChatGPT 使用人类反馈强化学习（RLHF）来解释提示并提供全面的响应 MedAlpaca 建立在 LLaMA 框架之上，并在指令调整格式的医学对话和 QA 文本上进行了微调 Robin-medical 使用 LMFlow 在医疗领域微调的 LLaMA 2.2 数据集 PubMedQA 1k 个专家标记的实例 问题来自研究文章的标题 内容来自摘要 长回答来自摘要结论 简洁的yes/no/maybe答案 MedQuAD 包含来自美国国立卫生研究院网站的 47,457 个 QA 对 MEDIQA2019 将挑战赛中得分3和4的答案视为黄金答案 LiveMedQA2017 MASH-QA 包括来自消费者健康领域的 34k QA 对 2.3 结果与讨论问题分类（本文认为前两个是幻觉问题。） 事实不一致 模型回答问题时未能正确回忆相关知识 查询不一致 既没有回答问题也没有适当地调用相关知识 离题 提供与主题相关的信息但不直接解决问题的答案。 模型没有进一步处理掌握的知识（例如归纳、演绎和逻辑推理） 应对这些挑战需要模型能够回忆事实知识、情境理解和推理能力 微调对医学领域的影响 [!note]+ why MedAplpaca 和 Robin-medical 之间的差异表明，指令学习比非指令调整更适合LLMs。 频率的测量 随机选择通用模型生成的 100 个样本 确定问题的关键词或主题，通常是疾病名称 采用 1950-2019 年之间这些关键词的平均频率。（数据来源是Google Ngram Viewer，将其作为自然世界中文本分布和预训练语料库的代理）对于有问题的回答，其关键词的平均频率低于好的回答。低频可能是产生幻觉的潜在原因 3. 缓解幻觉的方法(What) 提出了一个迭代的自我反思过程，该过程利用LLMs生成和完善响应的能力 方法包括三个循环 事实知识获取循环 知识一致回答循环 问题蕴涵回答循环 3.1 事实知识获取循环 模型基于所提供的问题生成背景知识 使用定制的无参考评分器对生成的知识进行事实性评估 Fs(\\mathbf{k}|D,Q)=\\sum_{t=1}^mlogP(k_t|\\mathbf{k_{"},{"title":"嗨！","date":"2024-07-12T16:00:00.000Z","url":"/posts/hello-world/","categories":[["undefined",""]],"content":"哦说声嗨，知道你一定会来"}]